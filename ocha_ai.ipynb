{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ocha_ai.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWjg1X3gfXNxoDgZalZOAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heromiya/ocha_ai/blob/master/ocha_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrFuC3BRPx_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ocha_ai\n",
        "!git clone https://github.com/heromiya/ocha_ai.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQsMfJ5AVYgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pillow keras==2.3.1 tensorflow-gpu==1.15 numpy pandas segmentation-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JGtIY9yLjdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil, tempfile, random, glob, subprocess, errno, datetime, numpy as np, matplotlib.pyplot as plt\n",
        "import tensorflow as tf, keras\n",
        "\n",
        "from PIL import Image\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D\n",
        "from keras.layers import  Dropout, Activation\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from random import shuffle\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import multi_gpu_model\n",
        "from tensorflow.python.client import device_lib\n",
        "import sys\n",
        "import pandas\n",
        "\n",
        "#pretrained_weights = sys.argv[1]\n",
        "#if pretrained_weights == 'None':\n",
        "#    pretrained_weights = None\n",
        "\n",
        "n_gpus = len([x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0eaoJjYL8sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directoly/folder prepration\n",
        "root_folder = 'ocha_ai/'\n",
        "\n",
        "training_ann_ras = root_folder + 'ann_ras/'\n",
        "training_img = root_folder + 'img/'\n",
        "test_img = root_folder + 'test_img/'\n",
        "\n",
        "#patch_root = tempfile.mkdtemp()\n",
        "patch_root = root_folder + '/patch/'\n",
        "#os.makedirs(patch_root, exist_ok=True)\n",
        "patch_ann = patch_root + '/patch_ann/'\n",
        "patch_img = patch_root + '/patch_img/'\n",
        "patch_pred = patch_root + '/patch_pred/'\n",
        "\n",
        "model_folder = root_folder + '/model/'\n",
        "\n",
        "test_results = root_folder + '/test_results/'\n",
        "timestamp =  str(datetime.datetime.now())\n",
        "log_d = root_folder + \"logs/\" + timestamp + '/'\n",
        "os.makedirs(log_d, exist_ok=True) \n",
        "\n",
        "os.makedirs(training_ann_ras, exist_ok=True)\n",
        "os.makedirs(patch_ann, exist_ok=True)\n",
        "os.makedirs(patch_img, exist_ok=True)\n",
        "os.makedirs(model_folder, exist_ok=True)\n",
        "os.makedirs(test_results, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX9omzAPMiwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patch_size = 256 \n",
        "\n",
        "batch_size = 512 # 256\n",
        "learning_rate = 0.001 # 0.00003 # 0.001 is a default of Adam in Keras.\n",
        "\n",
        "# Paramters for patch generation by gen_training_patch.sh\n",
        "n_patch = 100 # Too large number sometimes fails in training. More thab 100 is preferred.\n",
        "n_epoch = 100  # preferably >= 100 for operational model.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XEkpghUMp9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.system(\"bash -x \"+root_folder+\"/gen_training_patch.sh \" + training_ann_ras + \" \" + training_img + \" \" + patch_ann + \" \" + patch_img + \" \" + str(patch_size) + \" \" + str(n_patch))\n",
        "#!bash -x ocha_ai/gen_training_patch.sh \" + training_ann_ras + \" \" + training_img + \" \" + patch_ann + \" \" + patch_img + \" \" + str(patch_size) + \" \" + str(n_patch))\n",
        "%%script env MASKDIR=\"$training_ann_ras\" RASDIR=\"$training_img\" PATMASKDIR=\"$patch_ann\" PATRASDIR=\"$patch_img\" PATCH_SIZE=\"$patch_size\" N_PATCH=\"$n_patch\" bash\n",
        "\n",
        "echo \"### BEGIN $0 $(date +'%F_%T')\"\n",
        "\n",
        "function gen_patch() {\n",
        "    TIF=$1\n",
        "    IFS=' '\n",
        "    \n",
        "    JSON=$(gdalinfo -json \"$TIF\")\n",
        "    SIZE=($(echo $JSON | python3 -c \"import sys, json; print(json.load(sys.stdin)['size'])\" | tr -d [],))\n",
        "    X_SIZE=${SIZE[0]}\n",
        "    Y_SIZE=${SIZE[1]}\n",
        "    MASK_TIF=$MASKDIR/$(basename \"$TIF\" | sed 's/\\(\\.[a-zA-Z]\\{3\\}\\)$/-a\\1/g')\n",
        "    \n",
        "    upperRight=($(echo $JSON | python3 -c \"import sys, json; print(json.load(sys.stdin)['cornerCoordinates']['upperRight'])\" | tr -d [],))\n",
        "    lowerLeft=($(echo $JSON | python3 -c \"import sys, json; print(json.load(sys.stdin)['cornerCoordinates']['lowerLeft'])\" | tr -d [],))\n",
        "    #geoTransform=($(echo $JSON | python3 -c \"import sys, json; print(json.load(sys.stdin)['geoTransform'])\" | tr -d [],))\n",
        "    \n",
        "    #PIXEL_SIZE_X=${geoTransform[1]}\n",
        "    #PIXEL_SIZE_Y=$(echo ${geoTransform[5]} | tr -d \"-\")\n",
        "    PIXEL_SIZE_X=1\n",
        "    PIXEL_SIZE_Y=-1\n",
        "    PATCH_SIZE_GX=$(perl -e \"print $PATCH_SIZE * $PIXEL_SIZE_X\")\n",
        "    PATCH_SIZE_GY=$(perl -e \"print $PATCH_SIZE * $PIXEL_SIZE_Y\")\n",
        "    IMG_EXT=\"${lowerLeft[0]} ${lowerLeft[1]} ${upperRight[0]} ${upperRight[1]}\"\n",
        "       \n",
        "    # Patches for non-buildings\n",
        "    j=1\n",
        "    while [ $j -le $N_PATCH ]; do\n",
        "        PATCH_XMIN=$(perl -e \"print ${lowerLeft[0]} + rand($X_SIZE * $PIXEL_SIZE_X - $PATCH_SIZE_GX)\")\n",
        "        PATCH_YMIN=$(perl -e \"print ${lowerLeft[1]} + rand($Y_SIZE * $PIXEL_SIZE_Y - $PATCH_SIZE_GY)\")\n",
        "        PATCH_XMAX=$(perl -e \"print $PATCH_XMIN + $PATCH_SIZE_GX\")\n",
        "        PATCH_YMAX=$(perl -e \"print $PATCH_YMIN + $PATCH_SIZE_GY\")\n",
        "\t\n",
        "\t\n",
        "        FNAME=$(printf %09d $(shuf -i 0-1000000000 -n 1 )).png\n",
        "        PATCH_IMG=${PATRASDIR}/img/$FNAME\n",
        "        PATCH_MASK=${PATMASKDIR}/img/$FNAME\n",
        "        #gdalwarp -q -r lanczos -tr $RES $RES -te $PATCH_XMIN $PATCH_YMIN $PATCH_XMAX $PATCH_YMAX \"$TIF\" \"$PATCH_IMG\"\n",
        "        #gdalwarp -q -r lanczos -tr $RES $RES -te $PATCH_XMIN $PATCH_YMIN $PATCH_XMAX $PATCH_YMAX \"$MASK_TIF\" \"$PATCH_MASK\"\n",
        "        gdal_translate -q -of PNG -projwin $PATCH_XMIN $PATCH_YMAX $PATCH_XMAX $PATCH_YMIN \"$TIF\" \"$PATCH_IMG\"\n",
        "        gdal_translate -q -of PNG -projwin $PATCH_XMIN $PATCH_YMAX $PATCH_XMAX $PATCH_YMIN \"$MASK_TIF\" \"$PATCH_MASK\"\n",
        "\t\n",
        "        j=$(expr $j + 1)\n",
        "    done\n",
        "#done\n",
        "}\n",
        "export -f gen_patch\n",
        "\n",
        "echo \"$PATMASKDIR\" \"$PATRASDIR\"\n",
        "rm -rf \"$PATMASKDIR\" \"$PATRASDIR\" && mkdir -p $PATMASKDIR/img $PATRASDIR/img\n",
        "#for TIF in $(find \"$RASDIR\" -type f | grep -e \".*\\.png$\" -e \".*\\.tif$\"); do gen_patch $TIF; done\n",
        "parallel gen_patch {} ::: $(find \"$RASDIR\" -type f | grep -e \".*\\.tif$\" -e \".*\\.png$\")\n",
        "\n",
        "echo \"### END $0 $(date +'%F_%T')\" \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1J4d4bcMqxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 777 # any integer is okay.\n",
        "\n",
        "data_gen_args = dict(horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     validation_split=0.6329,\n",
        "                     rotation_range=180,\n",
        "                     shear_range=0.2,\n",
        "                     zoom_range=0.2,\n",
        "                     rescale=1./255\n",
        "                     )\n",
        "\n",
        "def mask_preprocessing(img):\n",
        "    img[img > 0] = 255\n",
        "    return img\n",
        "\n",
        "# Using ImageDataGenerator for images with more than 3 channels #4664\n",
        "# https://github.com/keras-team/keras/issues/4664\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen  = ImageDataGenerator(**data_gen_args, preprocessing_function = mask_preprocessing)\n",
        "\n",
        "train_image_generator = image_datagen.flow_from_directory(\n",
        "        patch_img,\n",
        "        class_mode=None,\n",
        "        seed=seed,\n",
        "        batch_size = batch_size,\n",
        "        target_size = (patch_size, patch_size),\n",
        "        subset='training')\n",
        "\n",
        "train_mask_generator = mask_datagen.flow_from_directory(\n",
        "        patch_ann,\n",
        "        class_mode=None,\n",
        "        seed=seed,\n",
        "        batch_size = batch_size,\n",
        "        target_size = (patch_size, patch_size),\n",
        "        color_mode='grayscale',\n",
        "        subset='training')\n",
        "\n",
        "\n",
        "test_image_generator = image_datagen.flow_from_directory(\n",
        "        patch_img,\n",
        "        class_mode=None,\n",
        "        seed=seed,\n",
        "        batch_size = batch_size,\n",
        "        target_size = (patch_size, patch_size),\n",
        "        subset='validation')\n",
        "\n",
        "test_mask_generator = mask_datagen.flow_from_directory(\n",
        "        patch_ann,\n",
        "        class_mode=None,\n",
        "        seed=seed,\n",
        "        batch_size = batch_size,\n",
        "        target_size = (patch_size, patch_size),\n",
        "        color_mode='grayscale',\n",
        "        subset='validation')\n",
        "\n",
        "\n",
        "train_generator = zip(train_image_generator, train_mask_generator)\n",
        "test_generator = zip(test_image_generator, test_mask_generator)\n",
        "\n",
        "#x, y= next(train_generator)\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def time_decay(epoch, initial_lrate):\n",
        "#    decay_rate = 0.01\n",
        "#    new_lrate = initial_lrate/(1+decay_rate*epoch)\n",
        "    new_lrate = learning_rate / (epoch+1)\n",
        "    return new_lrate\n",
        "\n",
        "lrate = LearningRateScheduler(time_decay,verbose=1)\n",
        "\n",
        "class PlotLearning(keras.callbacks.Callback):\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "        #self.fig = plt.figure()\n",
        "        self.logs = []\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        #choose a random test image and preprocess\n",
        "        path = np.random.choice(patch_files)\n",
        "        raw = Image.open(path)\n",
        "        raw = np.array(raw)/255.\n",
        "        raw = raw[:,:,0:3]\n",
        "        \n",
        "        #predict the mask \n",
        "        pred = model.predict(np.expand_dims(raw, 0))\n",
        "        \n",
        "        msk  = pred.squeeze()\n",
        "        msk = np.stack((msk,)*3, axis=-1)\n",
        "        msk[msk >= 0.5] = 1 \n",
        "        msk[msk < 0.5] = 0 \n",
        "        \n",
        "        #show the mask and the segmented image \n",
        "        combined = np.concatenate([raw, msk, raw* msk], axis = 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(combined)\n",
        "        plt.show()\n",
        "        \n",
        "\n",
        "def build_callbacks():\n",
        "    checkpointer = ModelCheckpoint(filepath = log_d + '/weights.' + timestamp + '.{epoch:04d}-{val_loss:.4f}.hdf5', verbose=0, save_weights_only=False, save_best_only=True)\n",
        "    callbacks = [checkpointer, lrate, PlotLearning()]\n",
        "    return callbacks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6FbhKkWM2WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Training\n",
        "# Configuration for multiple-band image data.\n",
        "# https://segmentation-models.readthedocs.io/en/latest/tutorial.html#training-with-non-rgb-data\n",
        "import segmentation_models as sm # https://github.com/qubvel/segmentation_models\n",
        "model = sm.Unet('resnet34', classes=1, activation='sigmoid')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "if n_gpus > 1:\n",
        "    model = multi_gpu_model(model, gpus=n_gpus)\n",
        "\n",
        "#if pretrained_weights is not None:\n",
        "#    model.load_weights(pretrained_weights) # Loading pretrained model.\n",
        "\n",
        "         \n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(lr=learning_rate),\n",
        "    loss = sm.losses.bce_jaccard_loss,\n",
        "    metrics = ['accuracy',sm.metrics.iou_score]\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhERbsDkM9Fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fnmatch import fnmatch\n",
        "root = patch_img\n",
        "pattern = \"*.png\"\n",
        "patch_files = []\n",
        "\n",
        "for path, subdirs, files in os.walk(root):\n",
        "    for name in files:\n",
        "        if fnmatch(name, pattern):\n",
        "            patch_files.append(os.path.join(path, name))\n",
        "\n",
        "train_steps = len(patch_files)/batch_size\n",
        "test_steps = len(patch_files)/batch_size\n",
        "model_history = model.fit_generator(train_generator, \n",
        "                                    epochs = n_epoch, \n",
        "                                    steps_per_epoch = train_steps,\n",
        "                                    validation_data = test_generator, \n",
        "                                    validation_steps = test_steps,\n",
        "                                    callbacks = build_callbacks(), \n",
        "                                    verbose = 1)\n",
        "\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(n_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}